{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The News Hour \n",
    "## Estimating the welfare impact of television news\n",
    "\n",
    "### by Matthew Baker and Lisa George\n",
    "\n",
    "In our paper, which you can find [at SSRN](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2694687), we describe what turns out to be a rather complex model of television news. This model includes several features, including:\n",
    "\n",
    "1. A viewership model with nested multinomial logit demand,\n",
    "2. A log-linear price model, \n",
    "3. Strategic interactions among stations with the aim of getting the most advertising revenues: Stations choose program menus to maximize their average nightly advertising revenues, which depend upon viewership shares and programming choices. \n",
    "\n",
    "Since there are a lot of moving parts - that we ourselves have to keep track of in details - we thought a notebook detailing various aspects of estimation would be a good idea, particularly if anyone else wanted to use some of the methods! In this first notebook, I will discuss data setup. \n",
    "\n",
    "# Data Setup\n",
    "\n",
    "The first thing to do, of course, is read in the data and render it in a manageable form. We need to revise settings and all that as well. We focus on the 2010 data, where our `sample` variable marks useable observations. We also exclude observations for which the variable `h` is not equal to twenty. This means that we are excluding observations from the twentieth hour of the day (e.g, 8 o'clock) because that is into prime time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjbaker\\Documents\\GitHub\\NewsHour\n"
     ]
    }
   ],
   "source": [
    "import ipystata\n",
    "import os\n",
    "\n",
    "CWD = os.getcwd()\n",
    "print(CWD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has to be a better way to do this than just running the above command and cutting and pasting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\mjbaker\\Documents\\GitHub\\NewsHour\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "clear all\n",
    "cd C:\\Users\\mjbaker\\Documents\\GitHub\\NewsHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\mjbaker\\Documents\\GitHub\\NewsHour\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "disp c(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "\n",
    "clear all\n",
    "set matsize 1000\n",
    "use \"Data\\NielsenKantarPanel.dta\" if year == 2010 & sample == 1 & h != 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make a variable marking all of our timeslots. Observe that the time slots are marked by hour, and then whether or not they are the first or second half of the hour. Accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2417240 missing values generated)\n",
      "(345320 real changes made)\n",
      "(345320 real changes made)\n",
      "(345320 real changes made)\n",
      "(345320 real changes made)\n",
      "(345320 real changes made)\n",
      "(345320 real changes made)\n",
      "(345320 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "\n",
    "gen     timeslot = 1 if h == 16 & half == 1\n",
    "replace timeslot = 2 if h == 16 & half == 2\n",
    "replace timeslot = 3 if h == 17 & half == 1\n",
    "replace timeslot = 4 if h == 17 & half == 2\n",
    "replace timeslot = 5 if h == 18 & half == 1\n",
    "replace timeslot = 6 if h == 18 & half == 2\n",
    "replace timeslot = 7 if h == 19 & half == 1\n",
    "replace timeslot = 8 if h == 19 & half == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Clean up the population variables so that they don't vary in each region or so they aren't missing for some observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2585760 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "bysort NDMACode: egen TotalPop1 = max(TotalPop)\n",
    "replace TotalPop=TotalPop1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem we face with the data is missing values for viewership under some level. Accordingly, we just replace these values with one-half the minimum reported value for each viewer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1519397 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "egen double minviewers=min(viewers), by(NDMAC)\n",
    "replace viewers=1/2*minviewers if viewers==. & affil==\"\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to employ an adjustment factor - which really just serves the purpose of not letting shares go above unity! A simple fix to this problem is to just suppose that each household can watch two shows per half-hour block, which effectively multiplies the population by two. From here on out, `Mpop` will function as our effective population variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2762560 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "scalar adjfactor=2\n",
    "egen double Mpop=mean(TotalPop), by(NDMACode)\n",
    "replace Mpop=Mpop*adjfactor\n",
    "label var Mpop \"Mean TotalPop by DMA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative measure of viewership, which is in some sense more accurate, is the American Community Survey reported households in the DMA. We can use this = along with the adjustment factor - to compute effective ACS eyeballs. In some very small markets, we get funny shares, so it is good to get rid of markets where this happens as well. \n",
    "\n",
    "Schematic:\n",
    "1. Multiply ACS by effective ACS adjustment factor\n",
    "2. Generate viewership shares\n",
    "3. Mark occurrence of excessive shares\n",
    "4. Mark markets with an occurrence of an excessive share\n",
    "5. Mark these markets for exclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2762560 real changes made)\n",
      "(27817 missing values generated)\n",
      "(103040 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "replace ACS_HH = ACS_HH*adjfactor\n",
    "gen double si = viewers/ACS_HH                                  \n",
    "egen double S = sum(si), by(NDMACode dow timeslot week)          \n",
    "egen double maxS = max(S), by(NDMACode)                          \n",
    "replace sample = 0 if maxS > 1                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(103040 observations deleted)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "keep if sample == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables marking different types of programming, according to the classifications that Lisa did. Our four categories will be:\n",
    "\n",
    "1. Local news (`lnews`) - requires expanding the existing definition a bit.\n",
    "2. National news (`nnews`)\n",
    "3. Other local programming - referred to as \"entertainment\" in the paper (`otherl`)\n",
    "4. Other cable programming (`otherc`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> )\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "rename lnews l_all\n",
    "gen lnews    = cond(l_all==1 & bc==1,1,0)\n",
    "gen cablenews= cond(Nstat==\"CNN\" | Nstat==\"BBCA\" | Nstat==\"HLN\" | Nstat==\"WGN\" | Nstat==\"FXNC\",1,0)\n",
    "gen nnews    = cond(news==1 & l_all==0 & (bc == 1 |cablenews == 1),1,0)\n",
    "gen otherl   = cond(news==0 & bc==1,1,0)\n",
    "gen otherc   = cond(bc==0 & lnews==0 & nnews==0 & otherl==0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark price data and mark and viewership data. Price data is defined as data for which we have a price per second (`pps != 0`), while viewership data is data for which we have a viewership shape (`si != .`). We also take this opportunity to drop out the spottier data on the first two time periods in our sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(656167 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "gen pricedata = cond(pps != ., 1, 0)\n",
    "gen viewdata  = cond(si != ., 1, 0)\n",
    "replace viewdata = 0 if timeslot ==1 | timeslot ==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will start assembling station-level variables by time slot across the four weeks of daily data in our data set. This focuses attention on average viewership over the time period (which is the relevant thing to look at for programming decisions), and also reduces our data to a manageable size! Before doing this, we pare down the data to our viewership data, and then create a station-level unique identifier number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(683382 observations deleted)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "keep if viewdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schematic for the following variables: \n",
    "\n",
    "1. Station-level numeric Id\n",
    "2. Mean viewership share for weekdays over sweeps month.\n",
    "3. Mean price-per-second for weekdays over sweeps month.\n",
    "4. Programming type - defined as a share of days broadcasting each type of programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1903095 missing values generated)\n",
      "(1876427 observations deleted)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "egen stationid = group(NDMAName Nstat)\n",
    "\n",
    "bysort stationid timeslot : egen double meansi    =mean(si)\n",
    "bysort stationid timeslot : egen double meanpps   =mean(pps)\n",
    "bysort stationid timeslot : egen double meanlnews =mean(lnews)\n",
    "bysort stationid timeslot : egen double meanotherl=mean(otherl)\n",
    "bysort stationid timeslot : egen double meannnews =mean(nnews)\n",
    "bysort stationid timeslot : egen double meanotherc=mean(otherc)\n",
    "bysort stationid timeslot :  gen keep =_n==_N\n",
    "\n",
    "keep if keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pare down the data so that we keep only what we need - it still is a huge data set, after all!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> HHispanic ACS_MedianHHIncome ACS_HHWhite ACS_MedianAge Mpop meansi meanpps meanlnews meanotherl me\n",
      "> annnews meanotherc\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "keep NDMAName NDMACode Nstat stationid timeslot affiliation local_station ACS_HH ACS_HHBlack ACS_HHHispanic ACS_MedianHHIncome ACS_HHWhite ACS_MedianAge Mpop meansi meanpps meanlnews meanotherl meannnews meanotherc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort resulting data, fill in missings, and set panel identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       panel variable:  stationid (unbalanced)\n",
      "        time variable:  timeslot, 3 to 8, but with gaps\n",
      "                delta:  1 unit\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "sort NDMACode stationid timeslot\n",
    "tsset stationid timeslot\n",
    "tsfill, full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe next bit of code back fills non-varying demographic variables for each observation. It loops over time periods and puts, for example, population data wherever it is missing at our panel-time unit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> HIncome ACS_HHWhite ACS_MedianAge Mpop NDMACode(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(13 real changes made)\n",
      "(1 real change made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(6 real changes made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(1 real change made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n",
      "(0 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "local stringReplace NDMAName Nstat affiliation\n",
    "local numberReplace stationid timeslot local_station ACS_HH ACS_HHBlack ACS_HHHispanic ACS_MedianHHIncome ACS_HHWhite ACS_MedianAge Mpop NDMACode\n",
    "\n",
    "forvalues i=3/8 {\n",
    "    foreach word of local stringReplace {\n",
    "        bysort stationid: replace `word'=`word'[_n+1] if `word'==\"\"\n",
    "        bysort stationid: replace `word'=`word'[_n-1] if `word'==\"\"\n",
    "    }\n",
    "    foreach word of local numberReplace {\n",
    "        bysort stationid: replace `word'=`word'[_n+1] if `word'==.\n",
    "        bysort stationid: replace `word'=`word'[_n-1] if `word'==.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some missing shares here and there, so we can fill these in without too much trouble. The best thing to do is interpolate over logs, as in this way we ensure that results are always positive - we can't have negative shares when we go to the form modelling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(21 missing values generated)\n",
      "(21 real changes made)\n",
      "(21 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "\n",
    "gen double lnsi = ln(meansi)\n",
    "bysort stationid: ipolate lnsi timeslot, gen(lnsid) epolate\n",
    "replace lnsi = lnsid if lnsi==.\n",
    "replace meansi = exp(lnsi) if meansi==.\n",
    "drop lnsid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code interpolates missing programming types where they are missing - there aren't a lot of places where this is the case, so there is virtually zero harm done. \n",
    "\n",
    "We then replace the most common programming type with a dummy for the analysis. Once again, stations almost never change viewership patterns during the week, but there are a handful of stations that do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(21 real changes made)\n",
      "(21 real changes made)\n",
      "(21 real changes made)\n",
      "(21 real changes made)\n",
      "(95994 missing values generated)\n",
      "(0 real changes made)\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "local AverageReplace meanlnews meanotherl meannnews meanotherc meanpps\n",
    "\n",
    "foreach word of local AverageReplace {\n",
    "    bysort stationid: ipolate `word' timeslot, gen(holder) epolate\n",
    "    replace `word'=holder if `word'==.\n",
    "    drop holder\n",
    "}\n",
    "\n",
    "gen lnews  = meanlnews > .5\n",
    "gen nnews  = meannnews > .5\n",
    "gen otherl = lnews == 0 & nnews == 0 & local_station\n",
    "gen otherc = (lnews == 0 & nnews == 0 & otherl == 0)\n",
    "\n",
    "drop meanlnews meanotherl meannnews meanotherc\n",
    "\n",
    "rename meansi si\n",
    "rename meanpps pps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have average shares and programming types per station per time period, we can start forming aggregates, which will figure into estimation when we start using the nested multinomial logit. Here, we compute shares by time period and programming type for each market, and also generate total viewership shares (and not viewing shares). We also make a variable called `owngroupshare` which returns each stations share within group of whatever type of broadcast they happen to be showing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "bysort NDMAC timeslot: egen double slnews=total(si*lnews)\n",
    "bysort NDMAC timeslot: egen double snnews=total(si*nnews)\n",
    "bysort NDMAC timeslot: egen double sotherl=total(si*otherl)\n",
    "bysort NDMAC timeslot: egen double sotherc=total(si*otherc)\n",
    "\n",
    "bysort NDMAC timeslot: egen double stotal=total(si)\n",
    "gen double so=1-stotal\n",
    "\n",
    "gen double owngroupshare=lnews*slnews+nnews*snnews+otherl*sotherl+otherc*sotherc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs and interaction terms, which also figure into estimation. Coincidentally, we generate these as doubles because they are often somewhat small, and we like to keep significant digits in making small predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "gen double ln_swg = ln(si/owngroupshare) \n",
    "\n",
    "gen double ln_swgXslnews=ln_swg*lnews   \n",
    "gen double ln_swgXsnnews=ln_swg*nnews    \n",
    "gen double ln_swgXsotherl=ln_swg*otherl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station-affiliation dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "gen NBC=(aff==\"NBC\")\n",
    "gen CBS=(aff==\"CBS\")\n",
    "gen ABC=(aff==\"ABC\")\n",
    "gen FOX=(aff==\"FOX\")\n",
    "gen CW= (aff==\"CW\")\n",
    "gen TEL=(aff==\"TEL\")\n",
    "gen UNI=(aff==\"UNI\")\n",
    "gen AZA=(aff==\"AZA\")\n",
    "gen MNT=(aff==\"MNT\")\n",
    "gen PBS=(aff==\"PBS\")\n",
    "gen TLF=(aff==\"TLF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional variables of interest, including a market-time identifier, and a market identifier (both are needed for our random effects scheme). Also, a time id, and a dependent variable. We then save it all as our working data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   timeslot |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          3 |     16,622       16.67       16.67\n",
      "          4 |     16,622       16.67       33.33\n",
      "          5 |     16,622       16.67       50.00\n",
      "          6 |     16,622       16.67       66.67\n",
      "          7 |     16,622       16.67       83.33\n",
      "          8 |     16,622       16.67      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     99,732      100.00\n",
      "\n",
      "   NDMACode |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "        500 |        402        0.40        0.40\n",
      "        501 |        744        0.75        1.15\n",
      "        502 |        456        0.46        1.61\n",
      "        503 |        474        0.48        2.08\n",
      "        504 |        750        0.75        2.83\n",
      "        505 |        612        0.61        3.45\n",
      "        506 |        654        0.66        4.10\n",
      "        507 |        438        0.44        4.54\n",
      "        508 |        642        0.64        5.19\n",
      "        509 |        426        0.43        5.61\n",
      "        510 |        630        0.63        6.24\n",
      "        511 |        732        0.73        6.98\n",
      "        512 |        726        0.73        7.71\n",
      "        513 |        474        0.48        8.18\n",
      "        514 |        624        0.63        8.81\n",
      "        515 |        636        0.64        9.45\n",
      "        516 |        414        0.42        9.86\n",
      "        517 |        642        0.64       10.50\n",
      "        518 |        648        0.65       11.15\n",
      "        519 |        438        0.44       11.59\n",
      "        520 |        462        0.46       12.06\n",
      "        521 |        696        0.70       12.75\n",
      "        522 |        480        0.48       13.24\n",
      "        523 |        396        0.40       13.63\n",
      "        524 |        654        0.66       14.29\n",
      "        525 |        432        0.43       14.72\n",
      "        526 |        492        0.49       15.21\n",
      "        527 |        624        0.63       15.84\n",
      "        528 |        672        0.67       16.51\n",
      "        529 |        594        0.60       17.11\n",
      "        530 |        438        0.44       17.55\n",
      "        531 |        462        0.46       18.01\n",
      "        532 |        384        0.39       18.40\n",
      "        533 |        696        0.70       19.10\n",
      "        534 |        660        0.66       19.76\n",
      "        535 |        606        0.61       20.36\n",
      "        536 |        438        0.44       20.80\n",
      "        537 |        390        0.39       21.19\n",
      "        538 |        378        0.38       21.57\n",
      "        539 |        684        0.69       22.26\n",
      "        540 |        438        0.44       22.70\n",
      "        541 |        438        0.44       23.14\n",
      "        542 |        654        0.66       23.79\n",
      "        543 |        438        0.44       24.23\n",
      "        544 |        684        0.69       24.92\n",
      "        545 |        420        0.42       25.34\n",
      "        546 |        438        0.44       25.78\n",
      "        547 |        468        0.47       26.25\n",
      "        548 |        666        0.67       26.92\n",
      "        549 |        498        0.50       27.42\n",
      "        550 |        438        0.44       27.85\n",
      "        551 |        480        0.48       28.34\n",
      "        553 |        444        0.45       28.78\n",
      "        554 |        516        0.52       29.30\n",
      "        555 |        468        0.47       29.77\n",
      "        556 |        690        0.69       30.46\n",
      "        557 |        648        0.65       31.11\n",
      "        558 |        456        0.46       31.57\n",
      "        559 |        558        0.56       32.13\n",
      "        560 |        654        0.66       32.78\n",
      "        561 |        678        0.68       33.46\n",
      "        563 |        420        0.42       33.88\n",
      "        564 |        486        0.49       34.37\n",
      "        565 |        504        0.51       34.88\n",
      "        566 |        468        0.47       35.34\n",
      "        567 |        690        0.69       36.04\n",
      "        569 |        468        0.47       36.51\n",
      "        570 |        456        0.46       36.96\n",
      "        571 |        624        0.63       37.59\n",
      "        573 |        456        0.46       38.05\n",
      "        574 |        426        0.43       38.47\n",
      "        575 |        444        0.45       38.92\n",
      "        576 |        504        0.51       39.42\n",
      "        577 |        474        0.48       39.90\n",
      "        581 |        468        0.47       40.37\n",
      "        582 |        366        0.37       40.74\n",
      "        584 |        354        0.35       41.09\n",
      "        588 |        390        0.39       41.48\n",
      "        592 |        378        0.38       41.86\n",
      "        597 |        528        0.53       42.39\n",
      "        598 |        522        0.52       42.91\n",
      "        600 |        432        0.43       43.35\n",
      "        602 |        678        0.68       44.03\n",
      "        603 |        414        0.42       44.44\n",
      "        604 |        390        0.39       44.83\n",
      "        605 |        402        0.40       45.24\n",
      "        606 |        438        0.44       45.67\n",
      "        609 |        582        0.58       46.26\n",
      "        610 |        396        0.40       46.66\n",
      "        611 |        372        0.37       47.03\n",
      "        612 |        456        0.46       47.49\n",
      "        613 |        558        0.56       48.04\n",
      "        616 |        630        0.63       48.68\n",
      "        617 |        630        0.63       49.31\n",
      "        618 |        648        0.65       49.96\n",
      "        619 |        378        0.38       50.34\n",
      "        622 |        678        0.68       51.02\n",
      "        623 |        678        0.68       51.70\n",
      "        624 |        426        0.43       52.12\n",
      "        625 |        444        0.45       52.57\n",
      "        627 |        480        0.48       53.05\n",
      "        628 |        462        0.46       53.51\n",
      "        630 |        672        0.67       54.19\n",
      "        631 |        516        0.52       54.70\n",
      "        632 |        474        0.48       55.18\n",
      "        633 |        426        0.43       55.61\n",
      "        634 |        438        0.44       56.05\n",
      "        635 |        648        0.65       56.70\n",
      "        636 |        432        0.43       57.13\n",
      "        637 |        390        0.39       57.52\n",
      "        638 |        450        0.45       57.97\n",
      "        639 |        528        0.53       58.50\n",
      "        640 |        708        0.71       59.21\n",
      "        641 |        636        0.64       59.85\n",
      "        642 |        444        0.45       60.29\n",
      "        643 |        480        0.48       60.77\n",
      "        644 |        468        0.47       61.24\n",
      "        647 |        504        0.51       61.75\n",
      "        648 |        390        0.39       62.14\n",
      "        649 |        384        0.39       62.53\n",
      "        650 |        618        0.62       63.15\n",
      "        651 |        396        0.40       63.54\n",
      "        652 |        396        0.40       63.94\n",
      "        656 |        420        0.42       64.36\n",
      "        657 |        486        0.49       64.85\n",
      "        658 |        408        0.41       65.26\n",
      "        659 |        654        0.66       65.91\n",
      "        661 |        450        0.45       66.36\n",
      "        662 |        438        0.44       66.80\n",
      "        669 |        354        0.35       67.16\n",
      "        670 |        426        0.43       67.59\n",
      "        671 |        624        0.63       68.21\n",
      "        673 |        492        0.49       68.70\n",
      "        675 |        378        0.38       69.08\n",
      "        676 |        414        0.42       69.50\n",
      "        678 |        366        0.37       69.87\n",
      "        679 |        354        0.35       70.22\n",
      "        682 |        402        0.40       70.62\n",
      "        686 |        414        0.42       71.04\n",
      "        687 |        372        0.37       71.41\n",
      "        691 |        438        0.44       71.85\n",
      "        692 |        414        0.42       72.27\n",
      "        693 |        426        0.43       72.69\n",
      "        698 |        438        0.44       73.13\n",
      "        702 |        420        0.42       73.55\n",
      "        705 |        390        0.39       73.94\n",
      "        709 |        468        0.47       74.41\n",
      "        710 |        528        0.53       74.94\n",
      "        711 |        480        0.48       75.42\n",
      "        716 |        444        0.45       75.87\n",
      "        717 |        438        0.44       76.31\n",
      "        718 |        462        0.46       76.77\n",
      "        722 |        408        0.41       77.18\n",
      "        724 |        366        0.37       77.55\n",
      "        725 |        384        0.39       77.93\n",
      "        734 |        504        0.51       78.44\n",
      "        736 |        492        0.49       78.93\n",
      "        737 |        378        0.38       79.31\n",
      "        743 |        378        0.38       79.69\n",
      "        744 |        378        0.38       80.07\n",
      "        746 |        426        0.43       80.50\n",
      "        749 |        444        0.45       80.94\n",
      "        751 |        606        0.61       81.55\n",
      "        752 |        420        0.42       81.97\n",
      "        753 |        618        0.62       82.59\n",
      "        754 |        366        0.37       82.96\n",
      "        755 |        438        0.44       83.40\n",
      "        756 |        408        0.41       83.80\n",
      "        757 |        354        0.35       84.16\n",
      "        758 |        348        0.35       84.51\n",
      "        759 |        474        0.48       84.98\n",
      "        760 |        426        0.43       85.41\n",
      "        762 |        420        0.42       85.83\n",
      "        764 |        456        0.46       86.29\n",
      "        765 |        450        0.45       86.74\n",
      "        767 |        474        0.48       87.22\n",
      "        770 |        600        0.60       87.82\n",
      "        771 |        558        0.56       88.38\n",
      "        773 |        390        0.39       88.77\n",
      "        789 |        408        0.41       89.18\n",
      "        790 |        660        0.66       89.84\n",
      "        800 |        480        0.48       90.32\n",
      "        801 |        420        0.42       90.74\n",
      "        802 |        420        0.42       91.16\n",
      "        803 |        732        0.73       91.90\n",
      "        804 |        432        0.43       92.33\n",
      "        807 |        654        0.66       92.99\n",
      "        810 |        486        0.49       93.47\n",
      "        811 |        408        0.41       93.88\n",
      "        813 |        438        0.44       94.32\n",
      "        819 |        552        0.55       94.87\n",
      "        820 |        612        0.61       95.49\n",
      "        821 |        360        0.36       95.85\n",
      "        825 |        678        0.68       96.53\n",
      "        828 |        426        0.43       96.96\n",
      "        839 |        642        0.64       97.60\n",
      "        855 |        420        0.42       98.02\n",
      "        862 |        738        0.74       98.76\n",
      "        866 |        444        0.45       99.21\n",
      "        868 |        408        0.41       99.61\n",
      "        881 |        384        0.39      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     99,732      100.00\n",
      "(95994 missing values generated)\n",
      "file AveragedData.dta saved\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "egen market=group(NDMACode)\n",
    "\n",
    "egen mt=group(NDMACode timeslot)\t\n",
    "\n",
    "sort market mt stationid\n",
    "\n",
    "tab timeslot, gen(timed)\n",
    "tab NDMACode, gen(markket)\n",
    "\n",
    "gen double dln=ln(si)-ln(so)\n",
    "gen double lnpps=ln(pps)\n",
    "\n",
    "gen double lnsiXnnews=lnsi*nnews\n",
    "gen double lnsiXotherl=lnsi*otherl\n",
    "\n",
    "sort market stationid mt\n",
    "\n",
    "save \"Data\\AveragedData.dta\", replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the next workbook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
