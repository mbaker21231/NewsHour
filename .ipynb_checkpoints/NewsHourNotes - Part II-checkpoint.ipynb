{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Hour - Part II\n",
    "\n",
    "In this notebook, we handle what is essentially the second half of the setup process. This involves rendering all of our data into a shape suitable for a more explicitly dynamic panel analysis. Basically, it amounts to doing some shifting operations in mata so that our data is set up a bit better than it was before. \n",
    "\n",
    "We also go ahead and estimate a dynamic version of the viewership model based on this. Estimation of this model is time-consuming, and to save time and trouble, we use the method described in [this paper](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=420371), which is also described in [this paper](http://www.stata-journal.com/article.html?article=st0354). \n",
    "\n",
    "To estimate things using this method, you can read the latter paper above, and should download and install the `AMCMC` `Stata` module from `SSC`. It can be found [here](https://ideas.repec.org/c/boc/bocode/s457613.html).  This also requires installation of the `moremata` module from [here](https://ideas.repec.org/c/boc/bocode/s455001.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some theoretical preliminaries\n",
    "\n",
    "As we state in the paper, we rely on what can be called a **Share Form Nested Multinomial Logit**. What is this, and how does it typically work? The basic idea, which originates with [Berry's 1994 paper](http://econpapers.repec.org/article/rjerandje/v_3a25_3ay_3a1994_3ai_3asummer_3ap_3a242-262.htm) is to render what is seemingly a difficult model into a linear form. \n",
    "\n",
    "First write viewership shares like this:\n",
    "$$ \n",
    "s_i=s_{i|b}s_b\n",
    "$$\n",
    "\n",
    "where $s_b$ in denotes the total viewing share among stations with type $b$ broadcasts, and $s_{i|b}$ denotes the within-group share of station $i$. In a nested multinomial logit model, a substitutability parameter $\\mu_b \\in [0,1]$ is used to characterize the degree to which items within a given type substitute for one another. Following Berry, define:\n",
    "\n",
    "$$\n",
    "D_b=\\sum_{k \\in S_b} e^{\\frac{u_k(b_k)}{1-\\mu_b}}\n",
    "$$\n",
    "\n",
    "so that we can write:\n",
    "\n",
    "$$\n",
    "s_{i|b}=\\frac{e^{\\frac{u_k(b_k)}{1-\\mu_b}}}{D_b}, \\quad s_b=\\frac{D_b^{1-\\mu_b}}{\\sum_{k \\in B}D_k^{1-\\mu_k}}\n",
    "$$\n",
    "\n",
    "Berry shows that this can be cast, with a little bit of algebra, into linear form:\n",
    "\n",
    "$$\n",
    "y_i=\\ln s_i-\\ln s_0=u_i(b)+\\mu_b \\ln s_{i|b}\n",
    "$$\n",
    "\n",
    "Berry details how to do this. The big thing to note about this last equation is that $\\ln s_{i|b}$ contains in part the dependent variable, and is hence endogenous. Berry recommends treating this problem with GMM, however, we will derive a likelihood expression for this, which I'm hoping might be the subject of another paper. \n",
    "\n",
    "Our basic approach is going to be to estimate a naive version of this equation for starting values, and then use a full-blown maximum likelihood equation by showing how the dependence filters through into the likelihood. That is, we will use the linear share form for $y_i$, but using (heuristically) a Jacobian transform to take care of the endogeneity problem duly noted by Berry; that is, if:\n",
    "\n",
    "$$\n",
    "f(y)dy=f(e)de\n",
    "$$\n",
    "\n",
    "and the distribution of $e$ is known - we shall assume it is normal with a two-way random effects structure - we can then get the distribution of $y$ - the viewership shares - through a simple transform:\n",
    "\n",
    "$$\n",
    "f(y) = f(e)\\frac{de}{dy}\n",
    "$$\n",
    "\n",
    "Let's begin the process by performing some preliminary data setup jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipystata\n",
    "import os\n",
    "\n",
    "CWD = os.getcwd()\n",
    "print(CWD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, a cut and paste job..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "clear all\n",
    "cd \"C:\\Users\\Matthew Baker\\Documents\\GitHub\\NewsHour\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get our data (which we assembled in Part I) - it is an averaged data set that should be ready to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "use \"Data\\AveragedData.dta\", clear\n",
    "set more off\n",
    "set seed 5150\n",
    "tsset stationid timeslot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling the Data into Dynamic form (i.e., the usual panel-like setup)\n",
    "\n",
    "One of the first things to do is get dynamic leads and lags to estimate some simple models that will somewhat resemble what we are going to do later with a complete set of random effects. One thing that is nice about doing this is that it provides somewhat of a guide as to how one might think about our more complex `Mata` code in `Stata` - we can also compare our random effects models with a more traditional two-way fixed effects model. \n",
    "\n",
    "Anyways, here are some lagged variables. We have lagged shares, and dummies indicating whether or not a broadcast of type $b$ in period $t$ follows a broadcast of type $b'$ in period $t-1$. We use these variables to capture the idea that people might like to watch news programs in a particular sequence over the evening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "gen double lsi=l.lnsi\n",
    "replace lsi=0 if lsi==.\n",
    "\n",
    "gen lnewslnews=lnews*l.lnews\n",
    "gen lnewsnnews=lnews*l.nnews\n",
    "gen nnewslnews=nnews*l.lnews\n",
    "gen nnewsnnews=nnews*l.nnews\n",
    "replace lnewslnews=0 if lnewslnews==.\n",
    "replace lnewsnnews=0 if lnewsnnews==.\n",
    "replace nnewslnews=0 if nnewslnews==.\n",
    "replace nnewsnnews=0 if nnewsnnews==.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have interactions of shares in the current period with each of the $t,t-1$ combinations of broadcasts that we care about - i.e., what the lagged share was last period, in the event that a station broadcast, say, national news last period, and is following it with local news this period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "gen double siXlnln=lnewslnews*lsi\n",
    "gen double siXlnnn=lnewsnnews*lsi\n",
    "gen double siXnnln=nnewslnews*lsi\n",
    "gen double siXnnnn=nnewsnnews*lsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also generate the total cumulative shares of local news broadcast up to a particular time slot during the night, and the total cumulative shares of national news broadcast up to a particular time slot during the night. The idea is to use these variables to capture the idea that news might get stale to later viewers because a lot of it has been watched earlier in the evening. Here goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "gen double totslnews=0\n",
    "sort stationid timeslot\n",
    "bysort stationid: replace totslnews=slnews[_n-1] if _n==2\n",
    "bysort stationid: replace totslnews=totslnews[_n-1]+slnews[2] if _n==3\n",
    "bysort stationid: replace totslnews=totslnews[_n-1]+slnews[3] if _n==4\n",
    "bysort stationid: replace totslnews=totslnews[_n-1]+slnews[4] if _n==5\n",
    "bysort stationid: replace totslnews=totslnews[_n-1]+slnews[5] if _n==6\n",
    "\n",
    "gen double totsnnews=0\n",
    "sort stationid timeslot\n",
    "bysort stationid: replace totsnnews=snnews[_n-1] if _n==2\n",
    "bysort stationid: replace totsnnews=totsnnews[_n-1]+snnews[2] if _n==3\n",
    "bysort stationid: replace totsnnews=totsnnews[_n-1]+snnews[3] if _n==4\n",
    "bysort stationid: replace totsnnews=totsnnews[_n-1]+snnews[4] if _n==5\n",
    "bysort stationid: replace totsnnews=totsnnews[_n-1]+snnews[5] if _n==6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these variables can be zero, and to keep the coefficients small and stable, we will typically use a transformed version of these variables in estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "gen double lnewstot=lnews*ln(1+totslnews)\n",
    "gen double nnewstot=nnews*ln(1+totsnnews)\n",
    "\n",
    "gen l_ACS_HH=ln(ACS_HH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line gives us our log-number of households variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ackerberg and Ryman (2006)](http://www.econ.ucla.edu/ackerber/pdfinal2.pdf) show that a multinomial logit can be really restrictive, and that it is helpful to include (functions of) group counts in estimation. They also note the role played by variation in the size of the choice set in identifying the parameters of a nested multinomial logit. Accordingly, we will include counts of each of the different types of broadcasts at given times in our estimation. These counts are easy to calculate, which can then be converted into functions as Ackerberg and Ryman (2006) suggest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "bysort mt: egen total_lnews=total(lnews)\n",
    "bysort mt: egen total_nnews=total(nnews)\n",
    "bysort mt: egen total_otherl=total(otherl)\n",
    "bysort mt: egen total_otherc=total(otherc)\n",
    "\n",
    "gen double lnewsn=lnews*ln(1+total_lnews)\n",
    "gen double nnewsn=nnews*ln(1+total_nnews)\n",
    "gen double otherln=otherl*ln(1+total_otherl)\n",
    "gen double othercn=otherc*ln(1+total_otherc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some preliminary preliminary estimates\n",
    "### The Viewership model\n",
    "\n",
    "We can basically now estimate a proto-viewership model, which doesn't worry about endogeneity or anything, but has the basic shape as the specification we shall employ. One needs the `a2reg` package to do this, as we include market-time and station-level fixed effects in this estimation. \n",
    "\n",
    "Here goes (without the A/R control variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "a2reg dln ln_swg ln_swgXslnews ln_swgXsotherl ln_swgXsnnews lnews otherl nnews lnewslnews lnewsnnews nnewslnews nnewsnnews lsi siXlnln siXlnnn siXnnln siXnnnn lnewstot nnewstot l_ACS_HH, individual(stationid) unit(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a version with the Ackerberg/Ryman controls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "a2reg dln ln_swg ln_swgXslnews ln_swgXsotherl ln_swgXsnnews lnews otherl nnews lnewslnews lnewsnnews nnewslnews nnewsnnews lsi siXlnln siXlnnn siXnnln siXnnnn lnewstot nnewstot l_ACS_HH lnewsn otherln nnewsn othercn, individual(stationid) unit(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lesson from the above is that the Ackerberg/Ryman stuff seems to matter in that it changes the estimates. Note hugely, but a little bit. We therefore are going to build it into our analysis. Of course, the `a2reg` command estimates with two-way fixed, not random, effects, and does not give standard errors, but it seems like a reasonable starting place. Interestingly, it seems as though the substitability of cable programming is quite high - (.95) is the estimated value, while local programming coefficients are much lower (add the estimated .95 to the interaction term - typically on the order of -.5 or -.8 to get the ultimate result.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some commenters wanted to see a pared-down model, let's estimate one of these and see where that gets us. Here, we drop all the stuff except Ackerberg/Ryman terms, dummies, and substitution parameters, but retain the two-way random effects structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "a2reg dln ln_swg ln_swgXslnews ln_swgXsotherl ln_swgXsnnews lnews otherl nnews l_ACS_HH lnewsn otherln nnewsn othercn, individual(stationid) unit(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is somewhat amazing how little this changes things...maybe we want to go with a model like this for the ultimate product? Anyways, what if we get rid of the two-way random effects - and just estimate a linear regression (which isn't the right way to do this given the endogeneity terms, but at least gives us some hints about parameter importance and stability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "reg dln ln_swg ln_swgXslnews ln_swgXsotherl ln_swgXsnnews lsi lnews otherl nnews l_ACS_HH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot thickens - perhaps we can get away with a very simple model...and reference people to this website if they have problems with our simple model...\n",
    "\n",
    "But in the interests of full disclosure, note that when one includes the lagged share variable, one does not really get the expected result...(`lsi` above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Anyways, we are first going to get everything ready to work in `Mata`, as the compiled code runs faster and also allows a bit more programming flexibility in implementation while still letting us use all Stata's great tools for graphing, displaying results, etc. We are going to use the values from `a2reg` as starting values and see if we can just run our viewership likelihood model on this. So, a first thing to do is to bring all these parameters into mata.\n",
    "\n",
    "__Convention:__ I am going to indent mata code by four spaces, kind of like regular Python code.\n",
    "\n",
    "We will rerun the above quietly again to get starting values (quietly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "quietly a2reg dln ln_swg ln_swgXslnews ln_swgXsotherl ln_swgXsnnews lnews otherl nnews lnewslnews lnewsnnews nnewslnews nnewsnnews lsi siXlnln siXlnnn siXnnln siXnnnn lnewstot nnewstot l_ACS_HH lnewsn otherln nnewsn othercn, individual(stationid) unit(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "mat bDyno    =e(b)\n",
    "mat sdmarDy  =e(sdunit)\n",
    "mat sdstaDy  =e(sdind)\n",
    "mat sdmodDy  =e(rmse)\n",
    "mat alphavDy =e(constant)\n",
    "\n",
    "mata:\n",
    "    bDyno    = st_matrix(\"bDyno\")\n",
    "    sdmarDy  = st_matrix(\"sdmarDy\")\n",
    "    sdstaDy  = st_matrix(\"sdstaDy\")\n",
    "    sdmodDy  = st_matrix(\"sdmodDy\")\n",
    "    alphavDy = st_matrix(\"alphavDy\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we will do is create a **structured object** to hold a bunch of variables, along with a function that initiates it, to make it easier to pass around large numbers of arguments between functions. Here is one such object, which we call `dynoInfo`. This collects all the lags and lagged shares, and a few other variables needed to fit the above model, into one thing we can hand around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata --mata\n",
    "    struct dynoInfo {\n",
    "        real matrix lnewslnews, lnewsnnews, nnewslnews, nnewsnnews, lsi,\n",
    "            siXlnln, siXlnnn, siXnnln, siXnnnn, lnewstot, nnewstot, l_ACS_HH,\n",
    "            lnewsn,otherln,nnewsn,othercn\n",
    "    }\n",
    "\n",
    "    struct dynoInfo dynoInfoInit(real matrix lnewslnews, lnewsnnews, nnewslnews, nnewsnnews,\n",
    "        lsi,siXlnln, siXlnnn,siXnnln, siXnnnn, lnewstot, nnewstot,l_ACS_HH,lnewsn,otherln,nnewsn,othercn)\n",
    "    {\n",
    "        struct dynoInfo scalar Dy\n",
    "        Dy.lnewslnews=lnewslnews\n",
    "        Dy.lnewsnnews=lnewsnnews\n",
    "        Dy.nnewslnews=nnewslnews\n",
    "        Dy.nnewsnnews=nnewsnnews\n",
    "        Dy.lsi=lsi\n",
    "        Dy.siXlnln=siXlnln\n",
    "        Dy.siXlnnn=siXlnnn\n",
    "        Dy.siXnnln=siXnnln\n",
    "        Dy.siXnnnn=siXnnnn\n",
    "        Dy.lnewstot=lnewstot\n",
    "        Dy.nnewstot=nnewstot\n",
    "        Dy.l_ACS_HH=l_ACS_HH\n",
    "        Dy.lnewsn=lnewsn\n",
    "        Dy.otherln=otherln\n",
    "        Dy.nnewsn=nnewsn\n",
    "        Dy.othercn=othercn\n",
    "        return(Dy)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going to much furher, we have to set up and specify a viewership likelihood in mata. I should more thoroughly describe what is going on here, and I will, but for now I will note that the likelihood function is essentially computed as is done in [Baltagi's book](http://www.wiley.com/WileyCDA/WileyTitle/productCd-EHEP003191.html), with the rather large exception of adding on a log-determinant adjustment for the endogeneity. I will add a description here as to where this comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata --mata\n",
    "    void logLikelihood2DynaA(M,todo,b,lnf,g,H)\n",
    "    {\n",
    "        real scalar mu_l,mu_o,mu_n,mu_c,eta_l,eta_n,\n",
    "            sdsta,sdmar,sdmod,i,T,N,lam1,\n",
    "            lam2,lam3,lam4,phi22,phi32\n",
    "        real matrix X,mt,id,mtp,idp,yp,Xp,Jn,Jt,En,Et,\n",
    "            Q1,Q2,Q3,Q4,OmegaInv,beta\n",
    "        struct dynoInfo scalar Dy\n",
    "\n",
    "        mu_l =(moptimize_util_xb(M,b,1))^2\n",
    "        mu_o =(moptimize_util_xb(M,b,2))^2\n",
    "        mu_n =(moptimize_util_xb(M,b,3))^2\n",
    "        mu_c =(moptimize_util_xb(M,b,4))^2\n",
    "        eta_l=moptimize_util_xb(M,b,5)\n",
    "        eta_o=moptimize_util_xb(M,b,6)\n",
    "        eta_n=moptimize_util_xb(M,b,7)\n",
    "        eta_ll=moptimize_util_xb(M,b,8)\n",
    "        eta_ln=moptimize_util_xb(M,b,9)\n",
    "        eta_nl=moptimize_util_xb(M,b,10)\n",
    "        eta_nn=moptimize_util_xb(M,b,11)\n",
    "\n",
    "        lam_own=moptimize_util_xb(M,b,12)\n",
    "        lam_ll=moptimize_util_xb(M,b,13)\n",
    "        lam_ln=moptimize_util_xb(M,b,14)\n",
    "\n",
    "        lam_nl=moptimize_util_xb(M,b,15)\n",
    "        lam_nn=moptimize_util_xb(M,b,16)\n",
    "        rho_l=moptimize_util_xb(M,b,17)\n",
    "        rho_n=moptimize_util_xb(M,b,18)\n",
    "        omega=moptimize_util_xb(M,b,19)\n",
    "        zeta_l=moptimize_util_xb(M,b,20)\n",
    "        zeta_o=moptimize_util_xb(M,b,21)\n",
    "        zeta_n=moptimize_util_xb(M,b,22)\n",
    "        zeta_c=moptimize_util_xb(M,b,23)\n",
    "        sdsta=exp(moptimize_util_xb(M,b,24))\n",
    "        sdmar=exp(moptimize_util_xb(M,b,25))\n",
    "        sdmod=exp(moptimize_util_xb(M,b,26))\n",
    "\n",
    "        alpha=moptimize_util_xb(M,b,27)\n",
    "\n",
    "        y     =moptimize_util_depvar(M,1)\n",
    "        lnswg =moptimize_util_depvar(M,2)\n",
    "        lnews =moptimize_util_depvar(M,3)\n",
    "        otherl=moptimize_util_depvar(M,4)\n",
    "        nnews =moptimize_util_depvar(M,5)\n",
    "        otherc=moptimize_util_depvar(M,6)\n",
    "        l_ACS_HH=moptimize_util_depvar(M,7)\n",
    "\n",
    "        id=moptimize_util_userinfo(M,1)\n",
    "        mt=moptimize_util_userinfo(M,2)\n",
    "        m =moptimize_util_userinfo(M,3)\n",
    "        Dy =moptimize_util_userinfo(M,4)\n",
    "        si =moptimize_util_userinfo(M,5)\n",
    "\n",
    "        beta=mu_l,mu_o,mu_n,mu_c,eta_l,eta_o,eta_n,\n",
    "            eta_ll,eta_ln,eta_nl,eta_nn,lam_own,lam_ll,\n",
    "            lam_ln,lam_nl,lam_nn,rho_l,rho_n,omega,zeta_l,zeta_o,zeta_n,zeta_c,alpha\n",
    "\n",
    "        X=lnews:*lnswg,otherl:*lnswg,nnews:*lnswg,otherc:*lnswg,\n",
    "            lnews,otherl,nnews,\n",
    "            Dy.lnewslnews,Dy.lnewsnnews,Dy.nnewslnews,Dy.nnewsnnews,\n",
    "            Dy.lsi,Dy.siXlnln,Dy.siXlnnn,Dy.siXnnln,Dy.siXnnnn,\n",
    "            Dy.lnewstot,Dy.nnewstot,l_ACS_HH,Dy.lnewsn,Dy.otherln,Dy.nnewsn,Dy.othercn,J(rows(lnews),1,1)\n",
    "\n",
    "        B=lnews,otherl,nnews,otherc\n",
    "\n",
    "        lnf=J(rows(m),1,.)\n",
    "        lnDetF=J(rows(m),6,.)\n",
    "        muVec=mu_l,mu_o,mu_n,mu_c\n",
    "        if (runiform(1,1)>.96) muVec,eta_l,eta_n,omega,zeta_l,zeta_o,zeta_n,zeta_c\n",
    "            for (i=1;i<=rows(m);i++) {\n",
    "                mtp=panelsubmatrix(mt,i,m)\n",
    "                idp=panelsubmatrix(id,i,m)\n",
    "                T=rows(uniqrows(mtp))\n",
    "                N=rows(uniqrows(idp))\n",
    "                yp=panelsubmatrix(y,i,m)\n",
    "                Xp=panelsubmatrix(X,i,m)\n",
    "                sip=panelsubmatrix(si,i,m)\n",
    "                Bp=panelsubmatrix(B,i,m)\n",
    "            \n",
    "                lam1=sdmod^2\n",
    "                lam2=T*sdsta^2+sdmod^2\n",
    "                lam3=N*sdmar^2+sdmod^2\n",
    "                lam4=T*sdsta^2+N*sdmar^2+sdmod^2\n",
    "                phi22=sdmod^2/lam2\n",
    "                phi32=sdmod^2/lam3\n",
    "                phi42=sdmod^2/lam4\n",
    "\n",
    "                Jn=J(N,N,1/N)\n",
    "                Jt=J(T,T,1/T)\n",
    "                En=I(N)-Jn\n",
    "                Et=I(T)-Jt\n",
    "\n",
    "                Q1=En#Et\n",
    "                Q2=En#Jt\n",
    "                Q3=Jn#Et\n",
    "                Q4=Jn#Jt\n",
    "                OmegaInv=(Q1/lam1+Q2/lam2+Q3/lam3+Q4/lam4)\n",
    "                lnDetOmega=-2*N*T*ln(sdmod)+(N-1)*ln(phi22)+(T-1)*ln(phi32)+ln(phi42)\n",
    "\n",
    "                lnf[i]=1/2*lnDetOmega-1/2*(yp-Xp*beta')'*OmegaInv*(yp-Xp*beta')\n",
    "\n",
    "                TimeVars=uniqrows(mtp)\t\n",
    "\n",
    "                for (z=1;z<=rows(TimeVars);z++) {\n",
    "                    siz=select(sip,mtp:==TimeVars[z])\n",
    "                    Bz=select(Bp,mtp:==TimeVars[z])\n",
    "                    sizBz=siz:*Bz\n",
    "                    sg=colsum(sizBz)\n",
    "                    Ng=colsum(sizBz:!=0)\n",
    "                    term=(Ng:>0):*(Ng:-1):*ln(1:-muVec)\n",
    "                    if (hasmissing(term)) lnDetF[i,z]=.\n",
    "                    else lnDetF[i,z]=rowsum(term)\n",
    "                }\n",
    "            }\n",
    "\n",
    "        lnDetF=B:*ln(1:-muVec)\n",
    "        if (hasmissing(lnf)) lnf=.\n",
    "        else lnf=colsum(lnf)\n",
    "        if (hasmissing(lnDetF)) lnf=.\n",
    "        else lnf=colsum(lnf) +colsum(rowsum(lnDetF))\n",
    "        if (runiform(1,1)>.96) colsum(rowsum(lnDetF)),lnf\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the data is sorted correctly (yet again - one can't be too careful about this!) and then pull in market, station id, and market-time identifiers. We also need to adjust parameters for our model because when using a linear estimation routine like `a2reg`, we use interactions for within-group shares. But when doing maximum likelihood, we will specify these parameters as-is, hence we have to back out the values by adding parameters and interactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "\n",
    "sort market stationid mt\n",
    "\n",
    "mata: \n",
    "    st_view(ma=.,.,\"market\")\n",
    "    st_view(id=.,.,\"stationid\")\n",
    "    st_view(mt=.,.,\"mt\")\n",
    "    \n",
    "    boDyno=bDyno\n",
    "    boDyno[1]=bDyno[1]+bDyno[2]\n",
    "    boDyno[2]=bDyno[1]+bDyno[3]\n",
    "    boDyno[3]=bDyno[1]+bDyno[4]\n",
    "    boDyno[4]=bDyno[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, here we can begin the process of:\n",
    "\n",
    "1. Setting up an `optimize` object in mata, \n",
    "2. Passing it initial values for parameters\n",
    "3. Passing it all variables from the model. \n",
    "\n",
    "This also serves as a way of mapping variables to the variable names we use in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata --mata\n",
    "    Z=moptimize_init()\n",
    "    moptimize_init_trace_dots(Z,\"on\")\n",
    "    moptimize_init_trace_params(Z,\"on\")\n",
    "    moptimize_init_evaluator(Z,&logLikelihood2DynaA())   \n",
    "    moptimize_init_evaluatortype(Z,\"d0\")    \n",
    "    moptimize_init_which(Z,\"max\")\n",
    "\n",
    "    moptimize_init_eq_indepvars(Z,1,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,2,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,3,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,4,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,5,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,6,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,7,\"\")\n",
    "    \n",
    "    moptimize_init_eq_indepvars(Z,8,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,9,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,10,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,11,\"\")\n",
    "\n",
    "    moptimize_init_eq_indepvars(Z,12,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,13,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,14,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,15,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,16,\"\")\n",
    "\n",
    "    moptimize_init_eq_indepvars(Z,17,\"\") \n",
    "    moptimize_init_eq_indepvars(Z,18,\"\")  \n",
    "    moptimize_init_eq_indepvars(Z,19,\"\")  \n",
    "\n",
    "    moptimize_init_eq_indepvars(Z,20,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,21,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,22,\"\")\n",
    "    moptimize_init_eq_indepvars(Z,23,\"\")\n",
    "    \n",
    "\n",
    "    moptimize_init_eq_indepvars(Z,24,\"\") \n",
    "    moptimize_init_eq_indepvars(Z,25,\"\")  \n",
    "    moptimize_init_eq_indepvars(Z,26,\"\")  \n",
    "    moptimize_init_eq_indepvars(Z,27,\"\")  \n",
    "\n",
    "    moptimize_init_depvar(Z,1,\"dln\")\n",
    "    moptimize_init_depvar(Z,2,\"ln_swg\")\n",
    "    moptimize_init_depvar(Z,3,\"lnews\")\n",
    "    moptimize_init_depvar(Z,4,\"otherl\")\n",
    "    moptimize_init_depvar(Z,5,\"nnews\")\n",
    "    moptimize_init_depvar(Z,6,\"otherc\")\n",
    "    moptimize_init_depvar(Z,7,\"l_ACS_HH\")\n",
    "\n",
    "\n",
    "    st_view(lnewslnews=.,.,\"lnewslnews\")\n",
    "    st_view(lnewsnnews=.,.,\"lnewsnnews\")\n",
    "    st_view(nnewslnews=.,.,\"nnewslnews\")\n",
    "    st_view(nnewsnnews=.,.,\"nnewsnnews\")\n",
    "    st_view(siXlnln=.,.,\"siXlnln\")\n",
    "    st_view(siXlnnn=.,.,\"siXlnnn\")\n",
    "    st_view(siXnnln=.,.,\"siXnnln\")\n",
    "    st_view(siXnnnn=.,.,\"siXnnnn\")\n",
    "    st_view(lnewstot=.,.,\"lnewstot\")\n",
    "    st_view(nnewstot=.,.,\"nnewstot\")\n",
    "    st_view(si=.,.,\"si\")\n",
    "    st_view(lsi=.,.,\"lsi\")\n",
    "    st_view(l_ACS_HH=.,.,\"l_ACS_HH\")\n",
    "    st_view(lnewsn=.,.,\"lnewsn\")\n",
    "    st_view(otherln=.,.,\"otherln\")\n",
    "    st_view(nnewsn=.,.,\"nnewsn\")\n",
    "    st_view(othercn=.,.,\"othercn\")\n",
    "    \n",
    "    Dy=dynoInfoInit(lnewslnews, lnewsnnews, nnewslnews, nnewsnnews,\n",
    "        lsi,siXlnln, siXlnnn,siXnnln, siXnnnn, lnewstot, nnewstot,l_ACS_HH,\n",
    "        lnewsn,otherln,nnewsn,othercn)\n",
    "\n",
    "    m=panelsetup(ma,1)\n",
    "    moptimize_init_userinfo(Z,1,id)\n",
    "    moptimize_init_userinfo(Z,2,mt)\n",
    "    moptimize_init_userinfo(Z,3,m)\n",
    "    moptimize_init_userinfo(Z,4,Dy)\n",
    "    moptimize_init_userinfo(Z,5,si)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a test to see if it is working..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata --mata\n",
    "moptimize_evaluate(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set up things to do an `AMCMC` run on the above, to see where everything winds up going...We also need to arrange starting values for parameters, which we do according to the estimated `a2reg` model, where we tack on standard deviations for other parameters. Setting up such a run can be read about in [my paper here](https://ideas.repec.org/a/tsj/stataj/v14y2014i3p623-661.html).\n",
    "\n",
    "Note we will use these as starting values in the full model, so we save those results as well. Be sure to include `.mmat` files in the `.gitignore` file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata --mata\n",
    "    bo=boDyno[1..23],sdmarDy,sdstaDy,sdmodDy,alphavDy\n",
    "    alginfo=\"mwg\",\"d0\",\"moptimize\"\n",
    "    b_start=amcmc(alginfo,&logLikelihood2DynaA(),bo,diag(abs(bo)/2),101,51,1,.4,arate=.,vals=.,lambda=.,.,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now save all these variables so we don't have to keep doing this - they can be good start values for what follows. I will save the last draw (so we have a starting value for a vector), but also the likelihood values, the acceptance rate from the draws, and all the draws themselves just so we have them if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "mata: \n",
    "    bo=b_start[rows(b_start),]\n",
    "    drawsbo=b_start\n",
    "    mata matsave DynoStarts23 bo drawsbo vals arate, replace\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A check of adding up and prediction...\n",
    "\n",
    "One thing to do before going much further is to see if predictions from the model - replete with error terms - actually match up with the shares that we have. Let's take a look. We can do this independently of the estimation above because we saved the results. Anyways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "mata:\n",
    "    mata matuse DynoStarts23, replace\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first step is to recreate our parameters (the ones that have been transformed, anyways). Next, we have to generate linear predictions, reshape variables, and run them through the model. Along the way, we also have to add in a Mata function that computes shares. \n",
    "\n",
    "**Note:** The `xBpUE` variable is in fact the entire linear prediction:\n",
    "\n",
    "$$\n",
    "\\hat{U}=X\\hat{\\beta}+\\hat{\\epsilon}\n",
    "$$\n",
    "\n",
    "without the share parameters. Hence, if one has $\\hat{U}$ and the share parameters, one should be able "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "mata:\n",
    "    bo[,1::4]=bo[,1::4]:^2\n",
    "    bo=bo[rows(bo),]\n",
    "    \n",
    "    st_view(ln_swg=.,.,\"ln_swg\")\n",
    "    st_view(lnews=.,.,\"lnews\")\n",
    "    st_view(otherl=.,.,\"otherl\")\n",
    "    st_view(nnews=.,.,\"nnews\")\n",
    "    st_view(otherc=.,.,\"otherc\")\n",
    "    st_view(dln=.,.,\"dln\")\n",
    "\n",
    "    xBpUE=dln:-  bo[1]:*ln_swg:*lnews:-\n",
    "         bo[2]:*ln_swg:*otherl:-\n",
    "         bo[3]:*ln_swg:*nnews:-\n",
    "         bo[4]:*ln_swg:*otherc\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I reshape data so that it is in `wide` form (which for some reason I called `Long` as a suffix in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "mata:\n",
    "    timeslots=6\n",
    "    lnewsLong=lnews\n",
    "    otherlLong=otherl\n",
    "    nnewsLong=nnews\n",
    "    othercLong=otherc\n",
    "    \n",
    "    lnewsLong=colshape(lnewsLong,6)\n",
    "    otherlLong=colshape(otherlLong,6)\n",
    "    nnewsLong=colshape(nnewsLong,6)\n",
    "    othercLong=colshape(othercLong,6)\n",
    "    xBpUE=colshape(xBpUE,6)\n",
    "\n",
    "    simSharesLong=J(rows(lnewsLong),cols(lnewsLong),.)\n",
    "    simSharesLong2=J(rows(lnewsLong),cols(lnewsLong),.)\n",
    "    simSharesLong3=J(rows(lnewsLong),cols(lnewsLong),.)\n",
    "    simSharesLong4=J(rows(lnewsLong),cols(lnewsLong),.)\n",
    "    marketIdLong=ma\n",
    "    marketIdLong=colshape(marketIdLong,6)\n",
    "    mLong=panelsetup(marketIdLong,1)\n",
    "end    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing shares given linear index values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to be done is to create some means of simulating shares, given linera index values. We will try this with several different methods, just to be safe, and to get a feel for if underflow problems are present, and if so, which method tends to do the best job with them. Anyways, here are some functions that calculate shares...after we develop a quick means of saving these so we can load them up when needed later - kind of like a Pythonish way of doing things in Stata..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "os.chdir(CWD+'\\\\MataFunctions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile sharemakers.do\n",
    "mata:\n",
    "    real matrix eshares_up(Uv,lnews,otherl,nnews,otherc,sigma_l,sigma_o,sigma_n,sigma_c)\n",
    "    {\n",
    "        sigg=lnews:*sigma_l:+otherl:*sigma_o:+nnews:*sigma_n:+otherc:*sigma_c\n",
    "        lu=exp(Uv:/(1:-sigg))\n",
    "        lu_l=colsum(lnews:*lu)\n",
    "        lu_n=colsum(nnews:*lu)\n",
    "        lu_o=colsum(otherl:*lu)\n",
    "        lu_c=colsum(otherc:*lu)\n",
    "        swg=lu:/(lu_l:*lnews:+lu_n:*nnews:+lu_o:*otherl:+lu_c:*otherc)\n",
    "        share=swg:*(lu_l:*lnews:+lu_n:*nnews:+lu_o:*otherl:+lu_c:*otherc):^(1:-sigg):/\n",
    "                  (1:+lu_l:^(1:-sigma_l):+lu_n:^(1:-sigma_n):+lu_o:^(1:-sigma_o):+lu_c:^(1:-sigma_c))\n",
    "        return(share)\n",
    "    }\n",
    "    \n",
    "    real matrix esharesStable(Uv,lnews,otherl,nnews,otherc,sigma_l,sigma_o,sigma_n,sigma_c)\n",
    "    {\n",
    "        sigg=lnews:*sigma_l:+otherl:*sigma_o:+nnews:*sigma_n:+otherc:*sigma_c\n",
    "        lnLu=Uv:/(1:-sigg)\n",
    "        if (colsum(lnews)>0) {\n",
    "            lnU=select(lnLu,lnews)\n",
    "            max=max(lnU)\n",
    "            lu_l=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_l=0\n",
    "        if (colsum(nnews)>0) {\n",
    "            lnU=select(lnLu,nnews)\n",
    "            max=max(lnU)\n",
    "            lu_n=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_n=0\n",
    "        if (colsum(otherl)>0) {\n",
    "            lnU=select(lnLu,otherl)\n",
    "            max=max(lnU)\n",
    "            lu_o=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_o=0\n",
    "        if (colsum(otherc)>0) {\n",
    "            lnU=select(lnLu,otherc)\n",
    "            max=max(lnU)\n",
    "            lu_c=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_c=0\n",
    "        swg=exp(lnLu):/(lu_l:*lnews:+lu_n:*nnews:+lu_o:*otherl:+lu_c:*otherc)\n",
    "        share=swg:*(lu_l:*lnews:+lu_n:*nnews:+lu_o:*otherl:+lu_c:*otherc):^(1:-sigg):/\n",
    "              (1:+lu_l:^(1:-sigma_l):+lu_n:^(1:-sigma_n):+lu_o:^(1:-sigma_o):+lu_c:^(1:-sigma_c))\t\n",
    "        return(share)\n",
    "    }\n",
    "    \n",
    "    real matrix esharesMoreStable(Uv,lnews,otherl,nnews,otherc,sigma_l,sigma_o,sigma_n,sigma_c)\n",
    "    {\n",
    "        sigg=lnews:*sigma_l:+otherl:*sigma_o:+nnews:*sigma_n:+otherc:*sigma_c\n",
    "        lnLu=Uv:/(1:-sigg)\n",
    "        if (colsum(lnews)>0) {\n",
    "            lnU=select(lnLu,lnews)\n",
    "            max=max(lnU)\n",
    "            lu_l=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_l=0\n",
    "        if (colsum(nnews)>0) {\n",
    "            lnU=select(lnLu,nnews)\n",
    "            max=max(lnU)\n",
    "            lu_n=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_n=0\n",
    "        if (colsum(otherl)>0) {\n",
    "            lnU=select(lnLu,otherl)\n",
    "            max=max(lnU)\n",
    "            lu_o=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_o=0\n",
    "        if (colsum(otherc)>0) {\n",
    "            lnU=select(lnLu,otherc)\n",
    "            max=max(lnU)\n",
    "            lu_c=exp(max):*colsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_c=0\n",
    "        lso=ln(1:+lu_l:^(1-sigma_l):+lu_o:^(1-sigma_o):+lu_n:^(1-sigma_n):+lu_c:^(1-sigma_c))\n",
    "        lnlu_l=ln(lu_l)\n",
    "        lnlu_o=ln(lu_o)\n",
    "        lnlu_n=ln(lu_n)\n",
    "        lnlu_c=ln(lu_c)\n",
    "        _editmissing(lnlu_l,0)\n",
    "        _editmissing(lnlu_o,0)\n",
    "        _editmissing(lnlu_c,0)\n",
    "        _editmissing(lnlu_n,0)\n",
    "        lsi=lnLu:-lnlu_l:*sigma_l:*lnews:-lnlu_n:*sigma_n:*nnews:-lnlu_o:*sigma_o:*otherl:-lnlu_c:*sigma_c:*otherc:-lso\n",
    "        return(exp(lsi))\n",
    "    }\n",
    "\n",
    "    real matrix esharesQuadPres(Uv,lnews,otherl,nnews,otherc,sigma_l,sigma_o,sigma_n,sigma_c)\n",
    "    {\n",
    "        sigg=lnews:*sigma_l:+otherl:*sigma_o:+nnews:*sigma_n:+otherc:*sigma_c\n",
    "        lnLu=Uv:/(1:-sigg)\n",
    "        if (colsum(lnews)>0) {\n",
    "            lnU=select(lnLu,lnews)\n",
    "            max=max(lnU)\n",
    "            lu_l=exp(max):*quadcolsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_l=0\n",
    "        if (colsum(nnews)>0) {\n",
    "            lnU=select(lnLu,nnews)\n",
    "            max=max(lnU)\n",
    "            lu_n=exp(max):*quadcolsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_n=0\n",
    "        if (colsum(otherl)>0) {\n",
    "            lnU=select(lnLu,otherl)\n",
    "            max=max(lnU)\n",
    "            lu_o=exp(max):*quadcolsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_o=0\n",
    "        if (colsum(otherc)>0) {\n",
    "            lnU=select(lnLu,otherc)\n",
    "            max=max(lnU)\n",
    "            lu_c=exp(max):*quadcolsum(exp(lnU:-max))\n",
    "        }\n",
    "        else lu_c=0\n",
    "        lso=ln(1:+lu_l:^(1-sigma_l):+lu_o:^(1-sigma_o):+lu_n:^(1-sigma_n):+lu_c:^(1-sigma_c))\n",
    "        lnlu_l=ln(lu_l)\n",
    "        lnlu_o=ln(lu_o)\n",
    "        lnlu_n=ln(lu_n)\n",
    "        lnlu_c=ln(lu_c)\n",
    "        _editmissing(lnlu_l,0)\n",
    "        _editmissing(lnlu_o,0)\n",
    "        _editmissing(lnlu_c,0)\n",
    "        _editmissing(lnlu_n,0)\n",
    "        lsi=lnLu:-lnlu_l:*sigma_l:*lnews:-lnlu_n:*sigma_n:*nnews:-lnlu_o:*sigma_o:*otherl:-lnlu_c:*sigma_c:*otherc:-lso\n",
    "        return(exp(lsi))\n",
    "    }\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having written this to a file, we can go back to the original directory and run the do file in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "disp c(pwd)\n",
    "do MataFunctions\\sharemakers.do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions really only differ in that they get progressively more careful about the handling of zeros. Note that the \"underflow\" trick is applied. Instead of calculating:\n",
    "\n",
    "$$\n",
    "\\ln(\\sum e^x_i)\n",
    "$$\n",
    "\n",
    "I use in some of the functions:\n",
    "\n",
    "$$\n",
    "M+\\ln(\\sum(e^{x_i-M})\n",
    "$$\n",
    "\n",
    "Where $M$ is the maximum value of the $x_i$'s. This turns out to be a pretty stable way of doing things, as one at least has a one term inside the log. \n",
    "\n",
    "Having set up shares functions, placeholders, linear indexes, and all that, we can now put together shares through the following simple loop. For comparison, we can also reshape the original shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "mata:\n",
    "    for (i=1;i<=rows(mLong);i++){\n",
    "        xBpUEp=panelsubmatrix(xBpUE,i,mLong)\n",
    "        lnewsLongp=panelsubmatrix(lnewsLong,i,mLong)\n",
    "        otherlLongp=panelsubmatrix(otherlLong,i,mLong)\n",
    "        nnewsLongp=panelsubmatrix(nnewsLong,i,mLong)\n",
    "        othercLongp=panelsubmatrix(othercLong,i,mLong)\n",
    "        for (t=1;t<=timeslots;t++) {\n",
    "            simSharesLong[mLong[i,1]::mLong[i,2],t]=\n",
    "                esharesStable(xBpUEp[,t],lnewsLongp[,t],otherlLongp[,t],\n",
    "                nnewsLongp[,t],othercLongp[,t],bo[1],bo[2],bo[3],bo[4])\n",
    "            simSharesLong2[mLong[i,1]::mLong[i,2],t]=\n",
    "                eshares_up(xBpUEp[,t],lnewsLongp[,t],otherlLongp[,t],\n",
    "                nnewsLongp[,t],othercLongp[,t],bo[1],bo[2],bo[3],bo[4])\n",
    "            simSharesLong3[mLong[i,1]::mLong[i,2],t]=\n",
    "                esharesMoreStable(xBpUEp[,t],lnewsLongp[,t],otherlLongp[,t],\n",
    "                nnewsLongp[,t],othercLongp[,t],bo[1],bo[2],bo[3],bo[4])\n",
    "            simSharesLong4[mLong[i,1]::mLong[i,2],t]=\n",
    "                esharesQuadPres(xBpUEp[,t],lnewsLongp[,t],otherlLongp[,t],\n",
    "                nnewsLongp[,t],othercLongp[,t],bo[1],bo[2],bo[3],bo[4])\n",
    "        }\n",
    "    }\n",
    "\n",
    "    siLong=si\n",
    "    siLong=colshape(siLong,6)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "    mata: max(abs(simSharesLong:-siLong))\n",
    "    mata: max(abs(simSharesLong2:-siLong))\n",
    "    mata: max(abs(simSharesLong3:-siLong))\n",
    "    mata: max(abs(simSharesLong4:-siLong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests we can breathe easy and adopt a simple approach to computing shares. We will, however, rely mainly on the `esharesStable` approach just to be safe! We see that there is little gain in doing things with quad precision, as everything is done that way in mata anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data and move onto the next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%stata\n",
    "save AveragedDataDyno.dta, replace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
